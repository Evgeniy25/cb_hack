{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN Layer:\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dense = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, adj, X):\n",
    "        adj = adj + torch.eye(adj.size(0))#.to(adj.device)\n",
    "        h = self.dense(X)\n",
    "        norm = adj.sum(1)**(-1/2)\n",
    "        h = norm[None, :] * adj * norm[:, None] @ h\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph construction module:  \n",
    "class Graph_tanh(nn.Module):\n",
    "    def __init__(self, num_nodes, k, alpha, device):\n",
    "        super(Graph_tanh, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.device = device\n",
    "        \n",
    "        self.A = nn.Parameter((torch.randn(num_nodes, num_nodes)+1), requires_grad=True)#.to(device)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        \n",
    "        adj = torch.tanh(0.1*self.A)\n",
    "        \n",
    "        if self.k:\n",
    "            mask = torch.zeros(idx.size(0), idx.size(0))#.to(self.device)\n",
    "            mask.fill_(float('0'))\n",
    "            s1,t1 = (adj + torch.rand_like(adj)*0.01).topk(self.k,1)\n",
    "            mask.scatter_(1,t1,s1.fill_(1))\n",
    "            adj = adj*mask\n",
    "            \n",
    "        return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_Directed_A(nn.Module):\n",
    "    def __init__(self, num_nodes, window_size, k, alpha, device):\n",
    "        super(Graph_Directed_A, self).__init__()\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.device = device\n",
    "        \n",
    "        self.e1 = nn.Embedding(num_nodes, window_size)\n",
    "        self.e2 = nn.Embedding(num_nodes, window_size)\n",
    "        self.l1 = nn.Linear(window_size,window_size)\n",
    "        self.l2 = nn.Linear(window_size,window_size)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        \n",
    "        m1 = torch.tanh(self.alpha*self.l1(self.e1(idx)))\n",
    "        m2 = torch.tanh(self.alpha*self.l2(self.e2(idx)))\n",
    "        adj = F.relu(torch.tanh(self.alpha*torch.mm(m1, m2.transpose(1,0))))\n",
    "        \n",
    "        if self.k:\n",
    "            mask = torch.zeros(idx.size(0), idx.size(0)).to(self.device)\n",
    "            mask.fill_(float('0'))\n",
    "            s1,t1 = (adj + torch.rand_like(adj)*0.01).topk(self.k,1)\n",
    "            mask.scatter_(1,t1,s1.fill_(1))\n",
    "            adj = adj*mask\n",
    "        \n",
    "        return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Neural Network\n",
    "class GNN(nn.Module):    \n",
    "    def __init__(self, num_nodes=108, window_size=10, nhidden=15, alpha=1, k=None, out_channels=108, device=None):\n",
    "        super(GNN, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.nhidden = nhidden\n",
    "        self.num_nodes = num_nodes\n",
    "        self.device = device\n",
    "        self.idx = torch.arange(self.num_nodes).to(device)\n",
    "        self.adj = None\n",
    "        self.z = (torch.ones(num_nodes, num_nodes) - torch.eye(num_nodes))#.to(device)\n",
    "        \n",
    "        #self.graph_struct = Graph_Directed_A(num_nodes,  window_size, k, alpha, device)\n",
    "        self.graph_struct = Graph_tanh(num_nodes, k, alpha, device)\n",
    "        self.conv1 = GCNLayer(window_size, nhidden)\n",
    "        self.bnorm1 = nn.BatchNorm1d(num_nodes)\n",
    "        self.conv2 = GCNLayer(nhidden, out_channels)\n",
    "        self.bnorm2 = nn.BatchNorm1d(num_nodes)\n",
    "        \n",
    "        #self.fc = nn.Linear(nhidden, out_channels)\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        #X = X.to(self.device)\n",
    "        self.adj = self.graph_struct(self.idx)\n",
    "        self.adj = self.adj * self.z\n",
    "        h = self.conv1(self.adj, X).relu()\n",
    "        h = self.bnorm1(h)\n",
    "        #skip = torch.squeeze(h)\n",
    "        h = self.conv2(self.adj, h).relu()\n",
    "        h = self.bnorm2(h)\n",
    "        h = torch.squeeze(h)\n",
    "        #h += skip\n",
    "                \n",
    "        #h = torch.cat(self.h, 1)\n",
    "        #output = self.fc(h).relu()\n",
    "        \n",
    "        return h\n",
    "    \n",
    "    def get_adj(self):\n",
    "        return self.adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цикл предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4445 [00:00<?, ?it/s]C:\\Users\\Alexk\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "<ipython-input-6-8d888104c340>:66: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  Train_X = torch.Tensor([np.array(x, dtype='float')])\n",
      " 12%|█▏        | 541/4445 [13:26<1:24:09,  1.29s/it]<ipython-input-6-8d888104c340>:96: UserWarning: Using a target size (torch.Size([173, 2, 1])) that is different to the input size (torch.Size([173, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(logits, Train_y)\n",
      "100%|██████████| 4445/4445 [1:51:06<00:00,  1.50s/it]  \n"
     ]
    }
   ],
   "source": [
    "for file_idx in tqdm(range(1, 4446)):\n",
    "    # загрузка файла:\n",
    "    try:\n",
    "        sheet1 = pd.read_excel('Test_input_'+str(file_idx)+'.xlsx') # месячные данные\n",
    "        df = sheet1.iloc[:,1:].copy()\n",
    "        Q = 1\n",
    "        try:\n",
    "            sheet2 = pd.read_excel('Test_input_'+str(file_idx)+'.xlsx', sheet_name='Quarterly') # квартальные данные\n",
    "        except:\n",
    "            Q = 0\n",
    "\n",
    "        # Объединение месячных и квартальных данных:\n",
    "        if Q == 1:\n",
    "            cols_sheet2 = sheet2.iloc[:,1:].columns # список столбцов в квартальных данных\n",
    "        cols_sheet1 = df.columns\n",
    "        if Q == 1:       \n",
    "            for column in cols_sheet2: # добавление квартальных столбцов к месячным с 0й инициализацией\n",
    "                df[column+'2'] = 0.0\n",
    "            for column in cols_sheet2: # Заполнение значений квартальных данных в общую таблицу (квартальное значение дублируется для всех 3х месяцев в квартале)\n",
    "                for i in range(len(df)):\n",
    "                    j = i//3\n",
    "                    df[column+'2'].iloc[i] = sheet2[column].iloc[j]\n",
    "\n",
    "        # индексирование:\n",
    "        start_forecast = df.shape[0] # индекс с первой неизвестной переменной\n",
    "        end_train_chunk = 0 # индекс последней известной переменной\n",
    "        startforecast_idxs = [] # список индексов в которых появляется первая неизвестная переменная для каждого ряда\n",
    "        mean_values = []\n",
    "        std_values = []\n",
    "        for i in range(df.shape[1]):\n",
    "\n",
    "            # finding indexes where forcasting starts:\n",
    "            if df.iloc[:,i][df.iloc[:,i] == 'Forecast'].index.empty:\n",
    "                idx = None\n",
    "            else:\n",
    "                idx = df.iloc[:,i][df.iloc[:,i] == 'Forecast'].index[0]\n",
    "                if idx < start_forecast:\n",
    "                    start_forecast = idx\n",
    "                if idx > end_train_chunk:\n",
    "                    end_train_chunk = idx\n",
    "            startforecast_idxs.append(idx)\n",
    "\n",
    "            # feature normalization and replacement:\n",
    "            mean_v = df.iloc[:idx,i].mean()\n",
    "            std_v = df.iloc[:idx,i].std()\n",
    "            df.iloc[:idx,i] = (df.iloc[:idx,i] - mean_v)/std_v\n",
    "            mean_values.append(mean_v)\n",
    "            std_values.append(std_v)\n",
    "\n",
    "        forcasting_length = df.shape[0] - start_forecast # Количество предсказываемых временных меток\n",
    "\n",
    "        # Параметры данных для модели:\n",
    "        num_nodes = df.shape[1] # количество \n",
    "        in_features = 30 # количество известных периодов в обучающем отрезке\n",
    "\n",
    "        # Разделение на обучающую и тестовую части:\n",
    "        # Train data:\n",
    "        train_mask = df.iloc[start_forecast-in_features:end_train_chunk, :]\n",
    "        train_mask = np.array((train_mask=='Forecast'))\n",
    "        train_chunk_length = in_features + (end_train_chunk - start_forecast) # длина обучающего временного отрезка\n",
    "        start_X = 0\n",
    "        stop_X = train_chunk_length-1\n",
    "        start_y = stop_X - (end_train_chunk - start_forecast) + 1\n",
    "        stop_y = start_y + forcasting_length - 1\n",
    "        x = df.loc[start_X:stop_X].mask(np.array(train_mask),0.0)\n",
    "        Train_X = torch.Tensor([np.array(x, dtype='float')])\n",
    "        Train_y = torch.Tensor([np.array(df.loc[start_y:stop_y], dtype='float')])\n",
    "\n",
    "        while stop_y < start_forecast - 1:\n",
    "            start_X += 1\n",
    "            stop_X += 1\n",
    "            start_y += 1\n",
    "            stop_y += 1\n",
    "            x = df.loc[start_X:stop_X].mask(np.array(train_mask),0.0)\n",
    "            Train_X = torch.cat((Train_X, torch.Tensor([np.array(x, dtype='float')])), 0)\n",
    "            Train_y = torch.cat((Train_y, torch.Tensor([np.array(df.loc[start_y:stop_y], dtype='float')])), 0)\n",
    "        Train_X = torch.transpose(Train_X, 1, 2)\n",
    "        Train_y = torch.transpose(Train_y, 1, 2)\n",
    "\n",
    "        # Test sample:\n",
    "        start_X += forcasting_length\n",
    "        stop_X += forcasting_length\n",
    "        x = df.loc[start_X:stop_X].mask(np.array(train_mask),0.0)\n",
    "        Test_X = torch.Tensor([np.array(x, dtype='float')])\n",
    "        Test_X = torch.transpose(Test_X, 1, 2)\n",
    "\n",
    "        # Создание модели:\n",
    "        model = GNN(num_nodes=num_nodes, window_size=train_chunk_length, nhidden=128, out_channels=forcasting_length)\n",
    "        opt = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Обучение:\n",
    "        for i in range(500):\n",
    "            model.train()\n",
    "            logits = model(Train_X)\n",
    "\n",
    "            loss = F.mse_loss(logits, Train_y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # Предсказание:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(Test_X)\n",
    "\n",
    "        y = logits.numpy()\n",
    "        for i in range(num_nodes):\n",
    "            y[i] = y[i] * std_values[i] + mean_values[i]\n",
    "        a = pd.DataFrame(np.transpose(y))\n",
    "\n",
    "        # Выгрузка ответа:\n",
    "        for i in range(len(cols_sheet1)):\n",
    "            if startforecast_idxs[i] is None:\n",
    "                continue\n",
    "            for j in range(sheet1.shape[0] - startforecast_idxs[i]):\n",
    "                k = startforecast_idxs[i] + j\n",
    "                sheet1.iloc[k,i+1] = a.iloc[j,i]\n",
    "        if Q==1:\n",
    "            for i in range(len(cols_sheet2)):\n",
    "                val = []\n",
    "                for k in range(0,len(a),3):\n",
    "                    val.append(np.sum(a.iloc[k:k+3,i+len(cols_sheet1)])/3)\n",
    "                if startforecast_idxs[i] is None:\n",
    "                    continue\n",
    "                for j in range(sheet2.shape[0] - startforecast_idxs[i]//3):\n",
    "                    k = startforecast_idxs[i]//3 + j - 1\n",
    "                    sheet2.iloc[k,i+1] = val[j]\n",
    "        with pd.ExcelWriter('Test_output_'+str(file_idx)+'.xlsx') as writer:  \n",
    "            sheet1.to_excel(writer, sheet_name='Monthly', index=False)\n",
    "            if Q==1:\n",
    "                sheet2.to_excel(writer, sheet_name='Quarterly', index=False,)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
